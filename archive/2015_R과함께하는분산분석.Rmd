R과 함께하는 분산분석
========================================================

배현웅, 문호석 지음
R통계학총서 시리즈3


```{r}
반복함수
reps <- function(strings, nrep) {
  a <- NULL
  for (c in strings) {
    a <- append(a, rep(c, nrep))
  }
  return(a)
}
```

1. 두 집단의 비교
---------------

### 1.1 독립적으로 추출된 두 표본의 비교

#### 1.1.1 분산이 알려져 있을 경우
```{r}
n1 <- 3
fmu <- 166
fvar <- 9
n2 <- 4
mmu <- 170
mvar <- 16
sumvar <- fvar / n1 + fvar / n2
z <- (0 - (fmu - mmu)) / sqrt(sumvar)
prob <- 1 - pnorm(z)
print(prob)

x <- seq(155, 180, by=0.1)
plot(x, dnorm(x, mean=fmu, sd=sqrt(fvar)), type="l")
text(170, 0.12, "N(166, sd=3)")
lines(x, dnorm(x, mean=mmu, sd=sqrt(mvar)), type="l", lty="dashed")
text(173, 0.11, "N(170, sd=4)")
```

#### 1.1.2 분산을 모를 경우
(1) 두 모집단의 분산이 다를 경우 t검정
```{r}
Aclass <- c(34, 61, 59, 46, 43, 44, 52, 43, 58, 67, 62, 57, 71, 49, 54, 
            43, 53, 57, 49, 56, 33)
Bclass <- c(42, 33, 46, 37, 43, 41, 10, 42, 55, 19, 17, 55, 26, 54, 60, 
            28, 62, 20, 53, 48, 37, 69, 42)
stem(Aclass)
stem(Bclass)
par(mfrow=c(1, 2))
qqnorm(Aclass)
qqline(Aclass)
qqnorm(Bclass)
qqline(Bclass)

# 수동 계산
Amean <- mean(Aclass)
Avar <- var(Aclass)
Bmean <- mean(Bclass)
Bvar <- var(Bclass)
n1 <- length(Aclass)
n2 <- length(Bclass)
DF <- ((Avar / n1 + Bvar / n2) ^ 2 / 
         (1 / (n1 - 1) * (Avar / n1) ^ 2 + 1 / (n2 - 1) * (Bvar / n2) ^ 2))
lower <- Amean - Bmean - qt(0.975, DF) * sqrt(Avar / n1 + Bvar / n2)
upper <- Amean - Bmean + qt(0.975, DF) * sqrt(Avar / n1 + Bvar / n2)
t <- (Amean - Bmean) / sqrt(Avar / n1 + Bvar / n2)
prob <- 1 - pt(t, DF)
print(prob)

# 두 모집단의 분산이 다를 경우 단측 t검정
t.test(Aclass, Bclass, alternative="greater")
```

(2) 두 분산이 같을 경우
```{r}
group1 <- c(9, 6, 8, 1, 2, -2, 4, -3, 4, 5)
group2 <- c(5, 3, -1, 2, 6, 3, -1, -3, -1, -4)
par(mfrow=c(1, 2))
boxplot(group1, xlab="group1")
boxplot(group2, xlab="group2")
qqnorm(group1)
qqline(group1)
qqnorm(group2)
qqline(group2)

# 두 모집단의 분산이 같을 경우 양측 t검정
t.test(group1, group2, var.equal=TRUE)
```

### 1.2 두 모분산의 동일성에 대한 검정
```{r}
var.test(group1, group2)
```

### 1.3 대응비교
```{r}
x <- c(52, 60, 63, 43, 46, 56, 62, 50)
y <- c(58, 62, 62, 48, 50, 55, 68, 57)
diff <- x - y
diff.mean <- mean(diff)
diff.sd <- sd(diff)
n <- length(x)
upper <- diff.mean + qt(0.975, n - 1) * diff.sd / sqrt(n)
lower <- diff.mean - qt(0.975, n - 1) * diff.sd / sqrt(n)
tvalue <- diff.mean / (diff.sd / sqrt(n))
pvalue <- 2 * pt(tvalue, n - 1)

print(upper)
print(lower)
print(tvalue)
print(pvalue)
t.test(diff)
```

2. 분산분석
------------

### 2.2 일원분산분석

#### 2.2.3 인자효과에 대한 검정
```{r}
weight <- c(30, 35, 28, 29, 25, 29, 34, # A
            25, 31, 28, 27, 23, 24, 31, # B
            20, 16, 17, 18, 18, 17, 20) # C
feed <- c(rep("A", 7), rep("B", 7), rep("C", 7))
pig <- data.frame(weight, feed)
par(mfrow=c(1, 2))
plot(weight ~ feed, pig)
with(pig, stripchart(weight ~ feed, vertical=TRUE, method="stack"))

res <- lm(weight ~ feed, pig)
summary(res)
anova(res)
```

#### 2.2.4 다중비교
가. 튜키의 HSD 검정법
```{r}
y <- c(120, 100, 155, 132, 138, # A
       86, 74, 99, 105, 95,     # B
       111, 150, 108, 92, 120,  # C
       125, 140, 132, 121, 123) # D
x <- c(rep("A", 5), rep("B", 5), rep("C", 5), rep("D", 5))
light <- data.frame(y, x)
result <- lm(y ~ x, light)
anova(result)
TukeyHSD(aov(y ~ x, light))
```

나. 던칸(Duncan) 검정법
책 참조 및 duncan.test {agricolae} 참조

다. 샤페(Scheffe) 검정법
책 참조 및 scheffe.test {agricolae} 참조


#### 2.2.5 기본 가정의 타당성 검토
나. Bartlett 검정법
```{r}
blood <- c(124, 116, 101, 118, 118, 120, 110, 127, 106, 130, 
           111, 101, 130, 108, 127, 129, 122, 103, 122, 127,
           117, 142, 121, 123, 121, 148, 141, 122, 139, 125,
           104, 128, 130, 103, 121, 119, 106, 107, 107, 115, 
           142, 139, 133, 120, 127, 149, 150, 149, 120, 116)
group <- c(rep("A", 10), rep("B", 10), rep("C", 10), rep("D", 10), 
           rep("E", 10))
datablood <- data.frame(blood, group)

bartlett.test(blood ~ group, datablood)
```


#### 2.2.6 인원분산분석모형-변량모형
```{r}
score <- c(76, 64, 85, 75, 
           58, 75, 81, 66,
           49, 63, 62, 46, 
           74, 71, 85, 90, 
           66, 74, 81, 79)
director <- reps(c("A", "B", "C", "D", "E"), 4)
selection <- data.frame(score, director)
res <- lm(score ~ director, selection)
anova(res)
```

### 이원분산분석

#### 2.3.1 반복실험이 아닌 경우
(1) 이원분산분석모형
```{r}
cost <- c(140, 100, 210, 180, 220, 200)
car.company <- expand.grid(company=c("K", "M"), car=c("1000", "1500", "1800"))
insurance <- data.frame(cost, car.company)
res <- lm(cost ~ car + company, insurance)
anova(res)
```

#### 2.3.2 반복실험인 경우
(1) 이원분산분석모형
```{r}
sales <- c(47, 43, 45, 51, 62, 68, 67, 71, 41, 39, 42, 46)
posi <- c("un", "un", "un", "un", "mi", "mi", "mi", "mi", "up", "up", "up", "up")
size <- c("n", "n", "w", "w", "n", "n", "w", "w", "n", "n", "w", "w")
breadcom <- data.frame(sales, posi, size)
par(mfrow=c(1, 1))
with(breadcom, interaction.plot(posi, size, sales, legend=T))
with(breadcom, interaction.plot(size, posi, sales, legend=T))
res <- lm(sales ~  posi * size, breadcom)
anova(res)
TukeyHSD(aov(sales ~ posi, breadcom))
```

